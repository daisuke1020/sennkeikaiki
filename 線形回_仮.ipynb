{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9bb0667-bf40-47bd-abff-ac5aa8a51f66",
   "metadata": {},
   "source": [
    "## 線形回帰の雛形モデルに問題ごとの作成コードを追加、上書きをしてスクラッチを完成させる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a3b572-bdda-4079-8c45-097b7a1bccf5",
   "metadata": {},
   "source": [
    "# 【問題1】仮定関数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c889c4-6f53-492b-b45a-903e1cd1548c",
   "metadata": {},
   "source": [
    "$$\n",
    "h_\\theta(x) =  \\theta_0 x_0 + \\theta_1 x_1 + ... + \\theta_j x_j + ... +\\theta_n x_n.   (x_0 = 1)\\\\\n",
    "$$\n",
    "は\n",
    "$$\n",
    "h_\\theta(x) = \\theta^T \\cdot x.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e6a0162-b131-430f-934e-36b0f9716618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _linear_hypothesis(self, X):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    Returns\n",
    "    -------\n",
    "     次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "    \"\"\"\n",
    "    self.X_ = np.insert(X,0,1,axis=1)           # Xの０列目に１を挿入\n",
    "    self.n_sample = X_.shape[0]            # Xの行の数を保管\n",
    "    self.n_featur = X_.shape[1]            # Xの列の数を保管\n",
    "    theta = np.random.rand(self.n_featur)  # thetaを初期化\n",
    "    self.theta = theta.reshape(-1,1) \n",
    "    self.theta_T = self.theta.T\n",
    "    \n",
    "    f_x = theta_T @ self.X_.T  #転置したthetaとX_をかける\n",
    "    \n",
    "    pass\n",
    "    return  f_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4153f-fecc-4d8e-910d-6a2dc52d8eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcf4618c-87ed-4465-9837-f7fc44e557b9",
   "metadata": {},
   "source": [
    "# 【問題2】最急降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dacbaa6-8388-40d0-ae7a-6e3c4ffb7789",
   "metadata": {},
   "source": [
    "## 最急降下法により学習させる実装を行なってください"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e44307-333b-447f-9282-95dccb600c6d",
   "metadata": {},
   "source": [
    "$$\n",
    "J(\\theta)=  \\frac{1 }{ 2m}  \\sum_{i=1}^{m} (h_\\theta(x^{(i)})-y^{(i)})^2.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m}[(h_\\theta(x^{(i)}) - y^{(i)} )x_{j}^{(i)}]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6aadfef2-d58b-4231-a8fa-b69d49810e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gradient_descent(X,error):\n",
    "    \"\"\"\n",
    "    説明を記述\n",
    "    引数\n",
    "    ---\n",
    "    X:  \n",
    "    error: y^ - y\n",
    "    \"\"\"\n",
    "    #theta = [0,0]#仮定関数の係数の初期値\n",
    "    GR = np.array([])\n",
    "    for j in range(self.n_feature):   #　 j列目のthetaの処理回数\n",
    "        for i in range(self.n_sample):#i行目のシグマの処理\n",
    "            GR = np.append(GR,(self.error[i])*self.X[i,j])\n",
    "        self.theta[j] = self.theta[j] - ((self.lr/self.n_sample)*GR.sum())\n",
    "        GR = np.array([])\n",
    "        \n",
    "    pass\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85251c83-d57a-4de7-9d81-178504d1d420",
   "metadata": {},
   "source": [
    "### 損失関数（目的関数）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b6e71d-f561-4755-8c74-b3821cdfe464",
   "metadata": {},
   "source": [
    "$$\n",
    "L(\\theta)=  \\frac{1 }{ m}  \\sum_{i=1}^{m} (h_\\theta(x^{(i)})-y^{(i)})^2.\n",
    "$$\n",
    "\n",
    "$$\n",
    "J(\\theta)=  \\frac{1 }{ 2m}  \\sum_{i=1}^{m} (h_\\theta(x^{(i)})-y^{(i)})^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ee9bd-5671-4de9-a189-fef77d535dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "667378d3-987b-49f7-bc5e-739c85e049b1",
   "metadata": {},
   "source": [
    "# 【問題3】推定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a173824-4d6a-47c9-acfb-8fd3d491159f",
   "metadata": {},
   "source": [
    "## 推定する仕組みを実装してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95d357b3-bc02-48d8-9a82-ea0896a5e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        answer = self._gradient_descent(X) @ X_test\n",
    "        \n",
    "        pass\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c40887c-d604-4acf-b1be-3595424a7e14",
   "metadata": {},
   "source": [
    "# 【問題4】平均二乗誤差"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c312f5-fff5-4f02-b0be-9219632a6329",
   "metadata": {},
   "source": [
    "## 線形回帰の指標値として用いられる平均二乗誤差（mean square error, MSE）の関数を作成してください"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbd648c-63ab-4594-a0e8-fbf304733e92",
   "metadata": {},
   "source": [
    "1. 推定結果を計算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b472cae-50a8-4b93-b11a-a6970ae8514e",
   "metadata": {},
   "source": [
    "$$\n",
    "h_\\theta(x_i) = \\theta^T \\cdot x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248219c1-7abf-491e-b218-a08d88569bc9",
   "metadata": {},
   "source": [
    "2. 実測値との差を計算【対応する数式の個所を書いてください】"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1faf3c-1db8-4e7f-9821-ea9da28041da",
   "metadata": {},
   "source": [
    "$$\n",
    "error_i = h_\\theta(x_i) - y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be1a21-637c-4f01-b040-92af1cd6c918",
   "metadata": {},
   "source": [
    "3. 1,2の2乗を計算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f15de5-e0d9-470a-8184-e6fd10675c26",
   "metadata": {},
   "source": [
    "$$\n",
    "squared error_i = error_i^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe1f873-9cb3-4667-8749-5e2a6c777f1b",
   "metadata": {},
   "source": [
    "4. 3の合計値を計算【対応する数式の個所を書いてください】"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bce64f6-9f30-4bdf-b4d3-bb5036162e30",
   "metadata": {},
   "source": [
    "$$\n",
    "sum squared error = \\sum_{i=1}^{m} squared error_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea5797-e002-4098-8127-da41f5c6fe06",
   "metadata": {},
   "source": [
    "5. データの長さで割って4の平均値を計算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b65e6-c0d9-4da9-aaf8-a8f43646a7cf",
   "metadata": {},
   "source": [
    "$$\n",
    "mean squared error = \\sum_{i=1}^{m} squared error_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21cd6850-ef12-4d0d-a2e2-6fc3e55c0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    ER = ([])\n",
    "    for i in range(self.n_sample):\n",
    "        ER = np.append(ER,(y_pred[i] - y[i])**2)\n",
    "    mse = 1/self.n_sample*ER.sum()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #mse = (1/self.n_sample*np.sum((y_pred - y)**2))\n",
    "    \n",
    "    pass\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca14d64-0933-44b7-9783-d767e6614304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec40061d-0bcf-4891-96e9-e2809e7bf7a9",
   "metadata": {},
   "source": [
    "# 【問題5】目的関数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be020747-9661-4e4b-a1cb-59479feb2c0f",
   "metadata": {},
   "source": [
    "## 線形回帰の 目的関数（損失関数） を実装してください"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd710d02-8534-4b9d-95a0-663778f99a71",
   "metadata": {},
   "source": [
    "$$\n",
    "J(\\theta)=  \\frac{1 }{ 2m}  \\sum_{i=1}^{m} (h_\\theta(x^{(i)})-y^{(i)})^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0931f99-275a-4d14-90f1-7aa284397a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca771f6-0303-4072-b363-208b3851220d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e965bb9-db59-434e-944b-f1af5132db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _loss_func(self,y_pred,y):\n",
    "\n",
    "    loss_ = 0\n",
    "    for i in range(self.n_sample):\n",
    "        loss_ += (y_pred[i] - y[i])**2\n",
    "        self.loss[i] = loss_\n",
    "        loss_v += loss_\n",
    "        self.val_loss[i] =loss_v\n",
    "    \n",
    "    loss_f = (0.5*loss_v)/self.n_sample    \n",
    "    \n",
    "    return loss_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d34d95c-dcd8-4b70-a3d8-8df1c2c89887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12d3fee5-f9c7-4eef-b636-50b809b207b9",
   "metadata": {},
   "source": [
    "# 【問題6】学習と推定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db441053-519b-4178-b790-843c9e4a2be2",
   "metadata": {},
   "source": [
    "## House Pricesコンペティションのデータに対してスクラッチ実装の学習と推定を行なってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3462a7a0-9e43-431b-8baa-9d4da65dbacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "    \n",
    "    パラメーター\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    \n",
    "    属性\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        #self.no_bias = no_bias\n",
    "        #self.verbose = verbose\n",
    "        \n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        \n",
    "        \n",
    "        self.theta = np.random.rand(2) \n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        # X_trainの調整\n",
    "        X_train = np.array(X_train)\n",
    "        XR = X_train.reshape(1,X_train.shape[0])\n",
    "        XT = XR.T\n",
    "        X = np.zeros((XT.shape[0],XT.shape[1] +1))\n",
    "        X_0 = 1\n",
    "        \n",
    "        # Xの追加\n",
    "        for i in range(X.shape[0]):\n",
    "            X[i] = np.append(X_0,XT[i])\n",
    "        \n",
    "        # Y_trainの調整\n",
    "        y_train = np.array(y_train)\n",
    "        \n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "#         self.y_pred = X @ self.theta.T\n",
    "#         print(self.y_pred)\n",
    "#         print(y_train)\n",
    "#         self.error = self.y_pred - y_train\n",
    "        \n",
    "        for i in range(self.iter):\n",
    "            self._linear_hypothesis(X)\n",
    "            self._gradient_descent(X)\n",
    "            self._loss_func(y_pred,y)\n",
    "\n",
    "        \n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        pass\n",
    "        return \n",
    "    \n",
    "    #---------問１--------\n",
    "    \n",
    "    def _linear_hypothesis(self, X):\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          訓練データ\n",
    "        Returns\n",
    "        -------\n",
    "         次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "        \"\"\"\n",
    "        self.X_ = np.insert(X,0,1,axis=1)           # Xの０列目に１を挿入\n",
    "        self.n_sample = X_.shape[0]            # Xの行の数を保管\n",
    "        self.n_featur = X_.shape[1]            # Xの列の数を保管\n",
    "        theta = np.random.rand(self.n_featur)  # thetaを初期化\n",
    "        self.theta = theta.reshape(-1,1) \n",
    "        self.theta_T = self.theta.T\n",
    "\n",
    "        f_x = self.theta_T @ self.X_.T  #転置したthetaとX_をかける\n",
    "\n",
    "        pass\n",
    "        return  f_x\n",
    "    \n",
    "    # --------問２--------\n",
    "    \n",
    "    def _gradient_descent(self,X):\n",
    "        \"\"\"\n",
    "        説明を記述\n",
    "        引数\n",
    "        ---\n",
    "        X:  \n",
    "        error: y^ - y\n",
    "        \"\"\"\n",
    "    \n",
    "        \n",
    "        #theta = [0,0]#仮定関数の係数の初期値\n",
    "        GR = np.array([])\n",
    "        for j in range(self.n_featur):   #　 j列目のthetaの処理回数\n",
    "            for i in range(self.n_sample):#i行目のシグマの処理\n",
    "                GR = np.append(GR,(error[i])*self.X[i,j])\n",
    "            self.theta[j] = self.theta[j] - ((self.lr/self.n_sample)*GR.sum())\n",
    "            GR = np.array([])\n",
    "\n",
    "        pass\n",
    "        return theta\n",
    "        \n",
    "                \n",
    "    #--------問３--------\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        answer = self._gradient_descent(X) @ X_test\n",
    "        \n",
    "        pass\n",
    "        return answer\n",
    "    \n",
    "    #--------問４--------\n",
    "    \n",
    "    def MSE(y_pred, y):\n",
    "        \"\"\"\n",
    "        平均二乗誤差の計算\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : 次の形のndarray, shape (n_samples,)\n",
    "          推定した値\n",
    "        y : 次の形のndarray, shape (n_samples,)\n",
    "          正解値\n",
    "        Returns\n",
    "        ----------\n",
    "        mse : numpy.float\n",
    "          平均二乗誤差\n",
    "        \"\"\"\n",
    "        ER = ([])\n",
    "        for i in range(self.n_sample):\n",
    "            ER = np.append(ER,(y_pred[i] - y[i])**2)\n",
    "        mse = 1/self.n_sample*ER.sum()\n",
    "\n",
    "\n",
    "\n",
    "        #mse = (1/self.n_sample*np.sum((y_pred - y)**2))\n",
    "\n",
    "        pass\n",
    "        return mse\n",
    "    \n",
    "    #--------問５--------\n",
    "    def _loss_func(self,y_pred,y):\n",
    "\n",
    "        loss_ = 0\n",
    "        for i in range(self.n_sample):\n",
    "            loss_ += (y_pred[i] - y[i])**2\n",
    "            self.loss[i] = loss_\n",
    "            loss_v += loss_\n",
    "            self.val_loss[i] =loss_v\n",
    "\n",
    "        loss_f = (0.5*loss_v)/self.n_sample    \n",
    "\n",
    "        return loss_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f8ad9f6f-39de-4b73-a835-8a48ebd26c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model #線形回帰のためのモジュール\n",
    "from sklearn.metrics import r2_score #R2を計算するためのモジュール\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score,recall_score,f1_score\n",
    "import warnings #ワーニング関連のモジュール？\n",
    "warnings.filterwarnings('ignore') #ワーニングが消える？\n",
    "\n",
    "csv_path = \"train.csv\" # ファイル名（パス）を指定する\n",
    "\n",
    "'''学習用データの読み込み'''\n",
    "df = pd.read_csv(\"train_1.csv\")\n",
    "#print(df)\n",
    "\n",
    "# 目的変数\n",
    "y = df.loc[:,[\"SalePrice\"]]\n",
    "\n",
    "#説明変数\n",
    "X = df.loc[:,[\"GrLivArea\"]]#,\"YearBuilt\"]]\n",
    "# X = np.array(X)\n",
    "# X_ = np.insert(X,0,1,axis=1) \n",
    "# X = pd.DataFrame(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f0d345e4-8fca-44a6-aa12-d3442a5ddefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータ分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "'''回帰モデルの作成'''\n",
    "#モジュール読み込み、モデル構築\n",
    "reg = ScratchLinearRegression(num_iter=10, lr = 0.05,no_bias=False, verbose=True)\n",
    "#モデルの学習\n",
    "reg.fit(X_train,y_train) \n",
    "# #予測値の算出\n",
    "# print(X_train)\n",
    "# print(type(X_train))\n",
    "# print(y_train)\n",
    "# #y_train_pred = reg.predict(X_train) #トレーニングデータでの予測\n",
    "# y_test_pred = reg.predict(X_test) #検証用データでの予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4502e-fb4e-4ebe-a5bd-f2c17c1e2804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaa758d7-9168-4caf-9a95-dcbdc441fc0f",
   "metadata": {},
   "source": [
    "# 【問題7】学習曲線のプロット"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fcbd70-6e9c-4e0a-8e36-698df50221b1",
   "metadata": {},
   "source": [
    "## 学習曲線を表示する関数を作成し、実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3322f-1053-465b-aad2-f35433bc537e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf5892-e7ab-4d0b-a929-48484b1d2fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be323ce0-9802-4c44-a527-5e38a3fccce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a122f4-a21b-4862-aff0-b3f20faa745c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa1f0f-d347-4c6f-b191-7298b491e258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2b45c9a-58c3-4fd4-a85f-23a4bd7be4e9",
   "metadata": {},
   "source": [
    "## 線形回帰の雛形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a34e9-bf8e-4c77-8355-bf1f76c8dbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8a2c6d-12de-4a10-b5a8-93a1abc977c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
